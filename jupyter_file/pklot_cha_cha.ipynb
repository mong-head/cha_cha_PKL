{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"pklot_final_term.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"MXeKQJwl4sDS"},"source":["# **Parking Lot Space Availability CNN (차차)**\n","This convolutional neural network performs binary classification task on visual input of a parking lot. Possible classes for individual parking lot spaces are empty and occupied. The segmentation of the image is done through the use of coordinates imported from a csv file."]},{"cell_type":"markdown","metadata":{"id":"25Jms7U34laM"},"source":["# **Code Initialization**\n","Modules and library imports, and mounting of drive"]},{"cell_type":"code","metadata":{"id":"QDY8bkUqi4hN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619304154644,"user_tz":420,"elapsed":57803,"user":{"displayName":"Julio Hurtado","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh0HYR4sCs934kmEJXIKCiV639n6rMOjdCi6Qgu=s64","userId":"14522591117255564378"}},"outputId":"451626db-c311-4714-bc3d-ff73da2907a4"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8iCHerq4bmxP"},"source":["'''\n","import tarfile\n","tar = tarfile.open(\"/content/drive/Shared drives/parkinglot/CNR-EXT_FULL_IMAGE_1000x750/CNR-EXT_FULL_IMAGE_1000x750.tar\")\n","tar.extractall(path=\"/content/drive/Shared drives/parkinglot/CNR-EXT_FULL_IMAGE_1000x750/\")\n","'''"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5pHjnJwjmLDH"},"source":["#!unzip \"/content/drive/Shared drives/parkinglot/CNR-EXT-Patches-150x150.zip\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fNruRQPpYb-G","colab":{"base_uri":"https://localhost:8080/","height":97},"executionInfo":{"status":"ok","timestamp":1578453150114,"user_tz":480,"elapsed":3265,"user":{"displayName":"Julio Hurtado","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC2b9JxlpqMkjW-ve5vI05h65uWd6c3x4237iGA=s64","userId":"14522591117255564378"}},"outputId":"40316f70-d6d8-4afc-b8f5-6218c436f366"},"source":["#Future imports\n","from __future__ import absolute_import\n","from __future__ import division\n","from __future__ import print_function\n","\n","#Utils imports\n","import os\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","import csv\n","from datetime import datetime\n","from PIL import Image\n","import cv2\n","import pickle as pkl\n","\n","#Tensorflow imports\n","import tensorflow as tf\n","from tensorflow import keras\n","try:\n","    %tensorflow_version 2.x\n","except Exception:\n","    pass\n","\n","#Sklearn imports\n","from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n","from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n","from sklearn.utils import compute_class_weight\n","\n","#Keras imports\n","from tensorflow.keras.applications.vgg19 import VGG19\n","from tensorflow.keras.utils import normalize\n","from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n","from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n","from tensorflow.keras.preprocessing import image\n","from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n","from tensorflow.keras.models import load_model"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["TensorFlow is already loaded. Please restart the runtime to change versions.\n"],"name":"stdout"},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"o3vSO-Wl5Xw0"},"source":["# **Definition of Global Variables**\n","Initialization of global variables that will be used through the entire code, these include the directory of the dataset, the logs, saved models, and input image parameters."]},{"cell_type":"code","metadata":{"id":"uMn6KlnXMHt5"},"source":["#Global variables definition\n","file_path = '/content/drive/Shared drives/parkinglot/'\n","model_path = file_path+'Best Model.hdf5'\n","logdir = file_path+\"IBML-Final-Project/Training Logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8ulJkl0yYpTx"},"source":["#Image parameters\n","image_width = 150\n","image_height = 150\n","channels = 3"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SQyKFzBJ5smn"},"source":["# **Data Acquisition**\n","Acquisition of empty and ocupied data instances, as well as the datset's ground truth. The images are attached to a numpy multidimensional array. Both classes are concatenated into a single array for inputs, and a single array for targets, and subsequently stored in a pickle file to be used later if necessary."]},{"cell_type":"code","metadata":{"id":"wthU4fL0YvNk"},"source":["class DataAcquisition():\n","    #Acquire busy class\n","    def busy_acquisition(image_width, image_height, channels):\n","        dir_path = file_path+'Dataset/Training/Training Set/Occupied/'\n","        X_busy = np.ndarray(shape=(len(os.listdir(dir_path)), image_height, image_width, channels), dtype=np.float32)\n","        for filename in os.listdir(dir_path):\n","            image_path = dir_path+filename\n","            print(str(len(os.listdir(dir_path))-(os.listdir(dir_path).index(filename)+1))+' files left in busy class')\n","            img = cv2.imread(image_path)\n","            img = cv2.resize(img, (150, 150))\n","            X_busy[os.listdir(dir_path).index(filename)] = img\n","        print(X_busy.shape)\n","        y_busy = np.ones((len(X_busy),1))\n","        return X_busy, y_busy\n","\n","    #Acquire free class\n","    def free_acquisition(image_width, image_height, channels):\n","        dir_path = file_path+'Dataset/Training/Training Set/Empty/'\n","        X_free = np.ndarray(shape=(len(os.listdir(dir_path)), image_height, image_width, channels), dtype=np.float32)\n","        print('X_free shape:'+str(X_free.shape))\n","        for filename in os.listdir(dir_path):\n","            image_path = dir_path+filename\n","            print(str(len(os.listdir(dir_path))-(os.listdir(dir_path).index(filename)+1))+' files left in free class')\n","            img = cv2.imread(image_path)\n","            img = cv2.resize(img, (150, 150))\n","            X_free[os.listdir(dir_path).index(filename)] = img\n","        print(os.listdir(dir_path).index)\n","        y_free = np.zeros((len(X_free),1))\n","        return X_free, y_free\n","\n","    #Concatenate the dataset\n","    def concatenate_dataset(X_busy, X_free, y_busy, y_free):\n","        length = len(X_busy) + len(X_free)\n","        print(length)\n","        X_raw = np.ndarray(shape=(length, image_height, image_width, channels), dtype=np.float32)\n","        for i in range(len(X_busy)):\n","            X_raw[i] = X_busy[i]\n","        for x in range(len(X_free)):\n","            X_raw[i+x+1] = X_free[x]\n","        y_raw = np.append(y_busy, y_free)\n","        return X_raw, y_raw\n","\n","    #Save dataset to file\n","    def save_dataset(X_raw, y_raw, file_path, X_busy, X_free, y_busy, y_free):\n","        np.savez((file_path+'IBML-Final-Project/Car Dataset v2.npz'), inputs_busy=X_busy, targets_busy=y_busy, inputs_free=X_free, targets_free=y_free)\n","        print('Saved!')\n","\n","    #Load dataset from file\n","    def load_dataset(file_path):\n","        dataset = np.load((file_path+'IBML-Final-Project/Car Dataset v2.npz'))\n","        X_raw = dataset['inputs']\n","        y_raw = dataset['targets']\n","        print('Loaded!')\n","        return X_raw, y_raw"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y-55OONe6gPB"},"source":["# **CNN Architechture Definition**\n","VGG19 is used as a base model for transfer learning, and additional layers are added, non-linear activation functions \"selu\" and \"relu\" are used for these layers, and the final layer uses \"softmax\" activation. Since the task involves binary classification, categorical crossentropy is used as the loss function. Hyperparameters of stochastic gradient descent, the optimizer selected for this architecture, include learning rate, learning rate decay, momentum, and dropout. A list of callbacks is defined to monitor and store logs of training, as well as saving the best overall model every epoch. Class weights are calculated to ensure that the dataset will not skew training through class imbalancement. Finally, the model is fitted."]},{"cell_type":"code","metadata":{"id":"lUR3KVOdY06Y"},"source":["class ModelDefinition():\n","\n","    def create_model(optimizer=keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True), dropout=0.1, init='uniform'):\n","      #Parameters\n","      loss_list = \"categorical_crossentropy\"\n","      test_metrics = 'accuracy'\n","      model_input = keras.Input(shape=(150, 150, 3))\n","\n","      #Base model\n","      base_model = VGG19(weights='imagenet', include_top=False)\n","      for layer in base_model.layers[:]:\n","          layer.trainable = False\n","      x = base_model(model_input)\n","      x = keras.layers.GlobalAveragePooling2D()(x)\n","      x = keras.layers.Dense(150, activation=\"selu\", kernel_initializer=init)(x)\n","      x = keras.layers.Dropout(dropout)(x)\n","      x = keras.layers.Dense(150, activation=\"selu\")(x)\n","      x = keras.layers.Dropout(dropout)(x)\n","\n","      #Output net\n","      y1 = keras.layers.Dense(128, activation='relu')(x)\n","      y1 = keras.layers.Dropout(dropout)(y1)\n","      y1 = keras.layers.Dense(64, activation='relu')(y1)\n","      y1 = keras.layers.Dropout(dropout)(y1)\n","      y1 = keras.layers.Dense(16, activation='relu')(y1)\n","      y1 = keras.layers.Dropout(dropout)(y1)\n","\n","      #Net connections to output layer\n","      y1 = keras.layers.Dense(2, activation='softmax')(y1)\n","\n","      #Model compilation\n","      model = keras.models.Model(inputs=model_input, outputs=y1)\n","      model.compile(loss=loss_list,\n","                    optimizer=optimizer,\n","                    metrics=['accuracy'])\n","      return model\n","\n","    #Model checkpoint for most accurate model selection\n","    def define_callbacks(model_path, logdir):\n","        checkpoint = ModelCheckpoint(model_path, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n","        tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n","        callbacks_list = [checkpoint, tensorboard_callback]\n","        return callbacks_list\n","\n","    #Compute class weights\n","    def class_weights(y_train, y_valid):\n","        class_weight_list = compute_class_weight('balanced', np.unique(y_train), y_train)\n","        classWeight = dict(zip(np.unique(y_train), class_weight_list))\n","        y_train=keras.utils.to_categorical(y_train, 2)\n","        y_valid=keras.utils.to_categorical(y_valid, 2) \n","        return classWeight, y_train, y_valid\n","\n","    #Model fit training\n","    def fit_train(X_train, X_valid, y_train, y_valid):\n","        history = model.fit(X_train, y_train, epochs=10,\n","                    validation_data=(X_valid, y_valid), \n","                    callbacks=callbacks_list, class_weight=classWeight)\n","        return history"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bxRxDufr8MHI"},"source":["# **Model Training**\n","Block that combines multiple classes and methods to generate the dataset, define the model, and subsequently train it."]},{"cell_type":"code","metadata":{"id":"cVkkOAckY4C6"},"source":["class ModelTraining():\n","    def do_stuff(image_width, image_height, channels, file_path):\n","        X_busy, y_busy = DataAcquisition.busy_acquisition(image_width, image_height, channels)\n","        X_free, y_free = DataAcquisition.free_acquisition(image_width, image_height, channels)\n","        X_raw, y_raw = DataAcquisition.concatenate_dataset(X_busy, X_free, y_busy, y_free)\n","        DataAcquisition.save_dataset(X_raw, y_raw, file_path, X_busy, X_free, y_busy, y_free)\n","        \n","        X_raw, y_raw = DataAcquisition.load_dataset(file_path)\n","        X_train, X_valid, y_train, y_valid = train_test_split(X_raw, y_raw, test_size=0.2, random_state=42)\n","        model = ModelDefinition.create_model()\n","        callbacks_list = ModelDefinition.define_callbacks(model_path, logdir)\n","        classWeight, y_train, y_valid = ModelDefinition.class_weights(y_train, y_valid)\n","        history = ModelDefinition.fit_train(X_train, X_valid, y_train, y_valid)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LiSmUGIp8itU"},"source":["# **Test Image Segmentation**\n","Reads parking lot space coordinates from a csv file, and stores them in variables in order to generate patches in the image for cropping. The cropped images correspond to the seg"]},{"cell_type":"code","metadata":{"id":"l8-Fw_VaY8Gv"},"source":["class ParkingLotSegmentation():\n","    def crop_image(img, x1, y1, x2, y2, x3, y3, x4, y4):\n","        top_left_x = min([x1,x2,x3,x4])\n","        top_left_y = min([y1,y2,y3,y4])\n","        bot_right_x = max([x1,x2,x3,x4])\n","        bot_right_y = max([y1,y2,y3,y4])\n","        roi = img[top_left_y:bot_right_y+1, top_left_x:bot_right_x+1]\n","        return roi\n","\n","    def define_patches(model, img, ax, ID, x, y, lot_width, lot_height, center_x, center_y, lot_angle, vacancy):\n","        cont = 0\n","        for i in range(len(ID)):\n","            patch_shape = np.ndarray((4,2))\n","            patch_shape[0,0] = float(x[i+cont])\n","            patch_shape[0,1] = float(y[i+cont])\n","            patch_shape[1,0] = float(x[i+cont+1])\n","            patch_shape[1,1] = float(y[i+cont+1])\n","            patch_shape[2,0] = float(x[i+cont+2])\n","            patch_shape[2,1] = float(y[i+cont+2])\n","            patch_shape[3,0] = float(x[i+cont+3])\n","            patch_shape[3,1] = float(y[i+cont+3])\n","            cont = cont + 3\n","            roi = ParkingLotSegmentation.crop_image(img, int(patch_shape[0,0]), int(patch_shape[0,1]), int(patch_shape[1,0]), int(patch_shape[1,1]), int(patch_shape[2,0]), int(patch_shape[2,1]), int(patch_shape[3,0]), int(patch_shape[3,1]))\n","            roi = cv2.resize(roi, (150, 150))\n","            roi_tr = np.ndarray(shape=(1,150,150,3), dtype=np.float32)\n","            roi_tr = np.expand_dims(roi, axis=0).astype(np.float32)\n","            prediction = model.predict(roi_tr)\n","            print('Slot '+str(ID[i])+': '+str(np.argmax(prediction)))\n","            if np.argmax(prediction) == 0.0:\n","                rect = patches.Polygon(patch_shape, linewidth=1,edgecolor='g',facecolor='none')\n","            else:\n","                rect = patches.Polygon(patch_shape, linewidth=1,edgecolor='r',facecolor='none')\n","            ax.add_patch(rect)\n","\n","    def csv_input(img, ax, file_path, model,camara_csv):\n","        with open(file_path+camara_csv, newline='') as csvfile:\n","            lot_csv = reader = csv.DictReader(csvfile)\n","            #img = cv2.resize(img,(2592,1944))\n","            free = 0  #add : free space num\n","    \n","            for row in lot_csv:\n","                #crop_img = img[(int(row['Y'])-int(row['H'])/2):(int(row['Y'])-int(row['H'])/2)+int(row['H']), (int(row['X'])-int(row['W'])/2):(int(row['X'])-int(row['W'])/2)+int(row['W'])]      \n","                #crop_img = img[int((int(row['Y'])-int(row['H'])/2)):int((int(row['Y'])-int(row['H'])/2)+int(row['H'])), int((int(row['X'])-int(row['W'])/2)):int((int(row['X'])-int(row['W'])/2)+int(row['W']))]\n","                crop_img = img[int(row['Y']):int(row['Y'])+int(row['H']) , int(row['X']):int(row['X'])+int(row['W'])]\n","                #roi = cv2.resize(roi, (150, 150))\n","                \n","                roi = cv2.resize(crop_img, (150, 150))\n","                roi_tr = np.ndarray(shape=(1,150,150,3), dtype=np.float32)\n","                roi_tr = np.expand_dims(roi, axis=0).astype(np.float32)\n","                prediction = model.predict(roi_tr)\n","                #print(str(np.argmax(prediction)))\n","                if np.argmax(prediction) == 0.0:\n","                    ec='g'\n","                    free = free + 1\n","                else:\n","                    ec='r'\n","                    \n","                #rect  = patches.Rectangle(((int(row['X'])-int(row['W'])/2), (int(row['Y'])-int(row['H'])/2)), int(row['W']), int(row['H']), edgecolor=ec, facecolor='none') \n","                #rect  = patches.Rectangle(int((int(row['X'])/2.592), int((int(row['Y']))/2.592), int(int(row['W'])/2.592), int(int(row['H'])/2.592), edgecolor=ec, facecolor='none'))\n","                rect  = patches.Rectangle((int(row['X']), int(row['Y'])), int(row['W']), int(row['H']), edgecolor=ec, facecolor='none')\n","                ax.add_patch(rect)\n","        return free"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"onhu3QPe_phu"},"source":["# **Testing**\n","Takes a parking lot image as an input, segments it using the coordinates from the provided csv file, and subsequently runs each segment through the classifier's predictor. The results are then graphed into the original image, representing the classes by green patches, if empty, and red patches, if occupied."]},{"cell_type":"code","metadata":{"id":"2xKSU4EmY_FE"},"source":["class ModelTesting():\n","    def predict_vacancy(file_path):\n","        #Load trained model\n","        model = load_model(model_path)\n","        print('done!')\n","\n","        #Segment parking lot\n","        parkinglot_img_list = ['CNR-EXT_FULL_IMAGE_1000x750/FULL_IMAGE_1000x750/OVERCAST/2015-11-16/camera8/2015-11-16_1708.jpg',\n","                               'CNR-EXT_FULL_IMAGE_1000x750/FULL_IMAGE_1000x750/OVERCAST/2015-11-16/camera8/2015-11-16_0722.jpg',\n","                               'CNR-EXT_FULL_IMAGE_1000x750/FULL_IMAGE_1000x750/RAINY/2016-02-12/camera9/2016-02-12_1742.jpg',\n","                               'CNR-EXT_FULL_IMAGE_1000x750/FULL_IMAGE_1000x750/SUNNY/2015-11-27/camera1/2015-11-27_1640.jpg',\n","                               'school_1_2592.jpg','school_2_2592.jpg','school_3_2592.jpg']\n","        camera_csv_list = ['CNR-EXT_FULL_IMAGE_1000x750/camera8.csv',\n","                           'CNR-EXT_FULL_IMAGE_1000x750/camera8.csv',\n","                           'CNR-EXT_FULL_IMAGE_1000x750/camera9.csv',\n","                           'CNR-EXT_FULL_IMAGE_1000x750/camera1.csv',\n","                           'school.csv','school.csv','school2.csv']\n","        for i in range(len(parkinglot_img_list)):\n","           #Read parking lot image\n","           img = cv2.imread(file_path+parkinglot_img_list[i])\n","           fig,ax = plt.subplots(figsize=(10, 10))\n","           img = cv2.resize(img,(2592,1944)) #plus\n","\n","           #Generate patches\n","           #ParkingLotSegmentation.define_patches(model, img, ax, ID, x, y, lot_width, lot_height, center_x, center_y, lot_angle, vacancy)\n","           free_num = ParkingLotSegmentation.csv_input(img, ax, file_path, model,camera_csv_list[i])\n","           ax.imshow(img)\n","           plt.show()\n","           print('free space : ',free_num)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IFU2jwm174sq"},"source":["# **If __main__ Statement**\n","End of the code!"]},{"cell_type":"code","metadata":{"id":"FkNqrjSi0gbO","cellView":"code","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"18OT9BzBGLW9Ge7VNinjt6clFuEI1BPdY"},"executionInfo":{"status":"ok","timestamp":1575369118105,"user_tz":-540,"elapsed":30503,"user":{"displayName":"Yujin","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDyjzWEgbzt-zQitElEkY0zPWAQMRELmLs6m3L_8Ls=s64","userId":"06090826674992943239"}},"outputId":"a3de05c7-9dd5-456f-ca43-c3023285c65c"},"source":["if __name__ == \"__main__\":\n","    #ModelTraining.do_stuff(image_width, image_height, channels, file_path)\n","    vacancy = ModelTesting.predict_vacancy(file_path)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}